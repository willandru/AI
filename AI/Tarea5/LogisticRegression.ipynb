{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29fddc26",
   "metadata": {},
   "source": [
    "1) \n",
    "Correr el ejemplo multiclase al final de:https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html, concuya y explique cuales son los hiper parámetros por defecto.\n",
    "\n",
    "2) \n",
    "Encontrar la derivada de J para un theta arbitratio en la Regresión Logística. Ver la presentaciòn de regresiòn logistica para encontrar las web de ayuda al respecto. Este punto debe hacerse a mano y escanear en PDF.\n",
    "\n",
    "\n",
    "3) \n",
    "Implementar (adecuar) los dos métodos descritos en: https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html#id13. Con los datos en el csv en teams carpeta semana 6 (data_classification.csv).\n",
    "\n",
    "\n",
    "Puede descargar el código en:https://github.com/bfortuner/ml-glossary \n",
    "\n",
    "Se espera que usted use estas funciones para implementar una clasificaciòn simple. Se le suministran las funciones se espera que usted las use, para este punto NO se debe usar una implementaciòn de la Regresión Logística en sklearn u otra librerìa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd83c0",
   "metadata": {},
   "source": [
    "# Ejemplo multiclase 'Iris dataset' de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e121b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053e10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cce47f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5efce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las etiquetas predichas son:  [0 0]\n",
      "Las probabilidades para cada clase son:  [[9.81583570e-01 1.84164159e-02 1.44983478e-08]\n",
      " [9.71340098e-01 2.86598715e-02 3.01821901e-08]]\n",
      "Puntaje de evaluar el dataset:  0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "print('Las etiquetas predichas son: ', clf.predict(X[:2, :]))\n",
    "print('Las probabilidades para cada clase son: ',clf.predict_proba(X[:2, :]))\n",
    "print('Puntaje de evaluar el dataset: ', clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114bf63f",
   "metadata": {},
   "source": [
    "Se trata de un ejemplo de clasificación multiclase ( 3 clases) del famoso dataset 'Iris'. Utilizamos la clase 'LogisticRegression' del modulo 'linear_model' de la libreria sklearn. Se hace una regresión logística por defecto pero inmediatemente se reporta un error.\n",
    "\n",
    "Al correr el ejemplo tal como esta escrito en la pagina indicada obtenemos el siguiente mensaje de error:\n",
    "    \"458: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\".\n",
    "Además, se nos indica \"Increase the number of iterations (max_iter) or scale the data\", entre otras sugerencias.\n",
    "\n",
    "Esto fue corregido modificando el parametro max_iter=100 que está por defecto a max_iter=1000. \n",
    "\n",
    "Para conocer los parametros por defecto de esta función podemos observarlos en la pagina online sugerida en el encabezado, se muestran a continuación:\n",
    "\n",
    "class sklearn.linear_model.LogisticRegression(\n",
    "\n",
    "    penalty='l2',\n",
    "    *, \n",
    "    dual=False, \n",
    "    tol=0.0001, \n",
    "    C=1.0, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    class_weight=None, \n",
    "    random_state=None, \n",
    "    solver='lbfgs', \n",
    "    max_iter=100, \n",
    "    multi_class='auto', \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    n_jobs=None, \n",
    "    l1_ratio=None)\n",
    "    \n",
    "  Al instanciar un objeto 'clf' de la clase LogisticRegression heredamos sus métodos. Podemos ver en el ejemplo que se utiliza .predict() para predecir la clase de las 2 primeras filas del dataset y este método retorna la etiqueta predicha. Con el método .predict_proba() se obtienen las probabilidades dadas para cada instancia por cada clase posible del dataset. Y por últimmo con el método .score() estámos obteniendo el porcentaje de instancias correctamente clasificadas por el el modelo con respecto a todo el dataset, que en este ejemplo fue el mismo conjunto de datos en el que se entreno el modelo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b7110",
   "metadata": {},
   "source": [
    "# Derivada funcion de costo J de la Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610031a",
   "metadata": {},
   "source": [
    "Mirar el anexo al final del pdf, se realizo el procedimiento a mano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfc182",
   "metadata": {},
   "source": [
    "# Clasificador Logístico sin librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05d0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c3d07",
   "metadata": {},
   "source": [
    "EXPLORACIÓN DEL DATASET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e9829e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('data_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27f1c2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suenio</th>\n",
       "      <th>estudio</th>\n",
       "      <th>pasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.855064</td>\n",
       "      <td>9.639962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.625440</td>\n",
       "      <td>0.058927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.828192</td>\n",
       "      <td>0.723199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.150955</td>\n",
       "      <td>3.899420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.477900</td>\n",
       "      <td>8.198181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     suenio   estudio  pasan\n",
       "0  4.855064  9.639962      1\n",
       "1  8.625440  0.058927      0\n",
       "2  3.828192  0.723199      0\n",
       "3  7.150955  3.899420      1\n",
       "4  6.477900  8.198181      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "380ca521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   suenio   100 non-null    float64\n",
      " 1   estudio  100 non-null    float64\n",
      " 2   pasan    100 non-null    int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 2.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eafb43a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suenio</th>\n",
       "      <th>estudio</th>\n",
       "      <th>pasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.534528</td>\n",
       "      <td>4.836464</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.027270</td>\n",
       "      <td>3.121408</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.022280</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.974605</td>\n",
       "      <td>2.085163</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.469398</td>\n",
       "      <td>4.203772</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.866485</td>\n",
       "      <td>7.733342</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.947841</td>\n",
       "      <td>9.945176</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           suenio     estudio   pasan\n",
       "count  100.000000  100.000000  100.00\n",
       "mean     5.534528    4.836464    0.55\n",
       "std      3.027270    3.121408    0.50\n",
       "min      0.022280    0.024946    0.00\n",
       "25%      2.974605    2.085163    0.00\n",
       "50%      6.469398    4.203772    1.00\n",
       "75%      7.866485    7.733342    1.00\n",
       "max      9.947841    9.945176    1.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bcd3b",
   "metadata": {},
   "source": [
    "SELECCIÓN DE CARACTERÍSTICAS Y ETIQUETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d37b2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['suenio', 'estudio']]\n",
    "Y=data[['pasan']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b32f4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))\n",
    "\n",
    "\n",
    "def predict(features, weights):\n",
    "    z = np.dot(features, weights)\n",
    "    return sigmoid(z)\n",
    "\n",
    "\n",
    "def cost_function(features, labels, weights):\n",
    "    observations = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels*np.log(predictions)\n",
    "\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-labels)*np.log(1-predictions)\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum() / observations\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def update_weights(features, labels, weights, lr):\n",
    "    '''\n",
    "    Vectorized Gradient Descent\n",
    "    Features:(200, 3)\n",
    "    Labels: (200, 1)\n",
    "    Weights:(3, 1)\n",
    "    '''\n",
    "    N = len(features)\n",
    "\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T,  predictions - labels)\n",
    "\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def decision_boundary(prob):\n",
    "    return (prob >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "def classify(predictions):\n",
    "    decision_boundary = np.vectorize(decision_boundary)\n",
    "    return decision_boundary(predictions).flatten()\n",
    "\n",
    "\n",
    "def train(features, labels, weights, lr, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            pass\n",
    "\n",
    "    return weights, cost_history\n",
    "\n",
    "\n",
    "def accuracy(predicted_labels, actual_labels):\n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))\n",
    "\n",
    "\n",
    "def plot_decision_boundary(trues, falses):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    no_of_preds = len(trues) + len(falses)\n",
    "\n",
    "    ax.scatter([i for i in range(len(trues))], trues, s=25, c='b', marker=\"o\", label='Trues')\n",
    "    ax.scatter([i for i in range(len(falses))], falses, s=25, c='r', marker=\"s\", label='Falses')\n",
    "\n",
    "    plt.legend(loc='upper right');\n",
    "    ax.set_title(\"Decision Boundary\")\n",
    "    ax.set_xlabel('N/2')\n",
    "    ax.set_ylabel('Predicted Probability')\n",
    "    plt.axhline(.5, color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5888800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los pesos antes del entrenamiento:  [[-0.48718359]\n",
      " [-0.80467342]]\n",
      "Los pesos después del entrenamiento:  [[ 0.14265135]\n",
      " [-0.01000105]]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "iters=1000\n",
    "\n",
    "weights = np.random.normal(loc=0.0, scale=1.0, size=(2, 1))\n",
    "print('Los pesos antes del entrenamiento: ', weights)\n",
    "weights , ch = train(X, Y, weights, lr, iters)\n",
    "print('Los pesos después del entrenamiento: ', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab444e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h= predict(X, weights)\n",
    "h = decision_boundary(h)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2304ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800000000000001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(h,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56c98b",
   "metadata": {},
   "source": [
    "El modelo es muy simple y no cuenta con regularización, intercepto (bias), y demás parametros que la libreria sklearn ya tiene implementados. \n",
    "\n",
    "Se obtuvo una exactitud final del 58%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
